[{"authors":null,"categories":null,"content":"The Brosi Lab is studying how the structure of biological communities impacts their stability and functioning in the context of anthropogenic environmental change, primarily using plant-pollinator interaction networks as a model system.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9ebae3f8e97c71b0a7f84536a868d12f","permalink":"https://models4data2theory.github.io/author/berry-brosi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/berry-brosi/","section":"authors","summary":"The Brosi Lab is studying how the structure of biological communities impacts their stability and functioning in the context of anthropogenic environmental change, primarily using plant-pollinator interaction networks as a model system.","tags":null,"title":"Berry Brosi","type":"authors"},{"authors":null,"categories":null,"content":"The Valdovinos Lab uses network analysis and mathematical modeling to understand and quantify the structure, dynamics, and function of biological communities, including their responses to environmental changes such as species extinctions, invasions, climate change, and fisheries. Our research focuses mostly on plant-pollinator networks and marine food webs.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a4aa0ebf0ca37834126bd5c5fc20d791","permalink":"https://models4data2theory.github.io/author/fernanda-valdovinos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fernanda-valdovinos/","section":"authors","summary":"The Valdovinos Lab uses network analysis and mathematical modeling to understand and quantify the structure, dynamics, and function of biological communities, including their responses to environmental changes such as species extinctions, invasions, climate change, and fisheries.","tags":null,"title":"Fernanda Valdovinos","type":"authors"},{"authors":null,"categories":null,"content":"Dr. Ian Breckheimer is a staff Research Scientist at Rocky Mountain Biological Laboratory. Originally from Saluda, North Carolina, Ian’s research focuses on how landscapes (and the plants and people that live there) are adapting to global change. Much of his work links field measurements of ecological processes such as plant growth and flowering to their landscape context via imagery collected from drones, airplanes, and satellites.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9048c1a91c8ae522547a85d20f3f7656","permalink":"https://models4data2theory.github.io/author/ian-breckheimer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ian-breckheimer/","section":"authors","summary":"Dr. Ian Breckheimer is a staff Research Scientist at Rocky Mountain Biological Laboratory. Originally from Saluda, North Carolina, Ian’s research focuses on how landscapes (and the plants and people that live there) are adapting to global change.","tags":null,"title":"Ian Breckheimer","type":"authors"},{"authors":null,"categories":null,"content":"My lab and I study how the interactions between species affect the structure and dynamics of ecological communities. Our work combines mathematical theory with observational and experimental approaches in an effort to advance our understanding of species-rich communities. Most of our work has focused on rocky intertidal, kelp forest, and freshwater stream systems. Primary topics of research include (i) developing methods for characterizing the strength and functional forms of species interactions, (ii) understanding the influence of direct and indirect effects in complex interaction networks, and (iii) quantifying patterns of individual diet specialization within populations of generalist predators to understand its consequences at the population and community level.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://models4data2theory.github.io/author/mark-novak/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mark-novak/","section":"authors","summary":"My lab and I study how the interactions between species affect the structure and dynamics of ecological communities. Our work combines mathematical theory with observational and experimental approaches in an effort to advance our understanding of species-rich communities.","tags":null,"title":"Mark Novak","type":"authors"},{"authors":null,"categories":null,"content":"My research focuses on the intricate web of plant-pollinator interactions, aiming to uncover the mechanisms sustaining ecosystem stability and persistence. By delving into the dynamics between plants and their pollinators, I seek to understand how these interactions are impacted by human-induced changes, such as climate fluctuations, and drought conditions. Ultimately, this research holds the key to preserving biodiversity, safeguarding food resources, and addressing fundamental ecological concerns vital for the continued survival of our species.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"89d169e5a43dfda573b0460cabba4580","permalink":"https://models4data2theory.github.io/author/taranjot-kaur/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/taranjot-kaur/","section":"authors","summary":"My research focuses on the intricate web of plant-pollinator interactions, aiming to uncover the mechanisms sustaining ecosystem stability and persistence. By delving into the dynamics between plants and their pollinators, I seek to understand how these interactions are impacted by human-induced changes, such as climate fluctuations, and drought conditions.","tags":null,"title":"Taranjot Kaur","type":"authors"},{"authors":null,"categories":null,"content":"Table of Contents  Overview Topics    Overview This workshop will help applied researchers better integrate ecological theory and sophisticated data analysis into the study of plant-pollinator networks. We cover the basics of ecological network analysis, with a focus on the statistical and mathematical tools needed to analyze and interpret ecological networks. We’ll cover the basics of network structure, how to fit models to network data, and how to use these models to make predictions about network stability.\nWe’d like participants to spend a bit of time before the workshop getting familiar with the basics of R and RStudio, as well as reviewing some fundamental mathematical concepts we will rely on heavily in the workshop. We’ve provided some self-study modules to help everyone get up to speed, and we ask that participants reserve 5-10 hours before the workshop to work through these “pre-work modules”.\nDuring the 3-day workshop, we’ll start big (describing network structure), go small (model-fitting for characterizing pairwise interactions), and go big again (linking structure and interaction strengths to network stability). We’ll move between data processing, statistical methods, and mathematical theory. We’ll mix lectures, hands-on exercises, and coding sessions.\nTopics  Prework - R and RStudio Before you arrive at RMBL. Tutorial on setting up R and Rstudio.   Prework - R Data Basics Before you arrive at RMBL. Intro to data structures, help pages, and variable types in R.   Networks  Analysis of structure   Interactions Fitting models to data   Dynamics Dynamics and stability   Of Potential Interest Supplementary materials   ","date":1724371200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1724371200,"objectID":"a98a8836220067f37599a398a7c77b75","permalink":"https://models4data2theory.github.io/courses/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/","section":"courses","summary":"Table of Contents  Overview Topics    Overview This workshop will help applied researchers better integrate ecological theory and sophisticated data analysis into the study of plant-pollinator networks. We cover the basics of ecological network analysis, with a focus on the statistical and mathematical tools needed to analyze and interpret ecological networks.","tags":null,"title":"Workshop Content","type":"book"},{"authors":null,"categories":null,"content":"Before you arrive at RMBL.\nTutorial on setting up R and Rstudio.\nOverview This is a tutorial on how to install the R language and RStudio development environment. It was modified from here.\nThe tutorial will help you set up your computer to use R. It is for you if you need to learn how to:\n Install R on your computer Install the RStudio IDE Install packages, using the dplyr R package as an example.  You can skip this tutorial if you’ve already done these things.\nIs this tutorial for you? Do you need to work through the tutorial? Take the quiz below to find out.\n::: {.webex-check .webex-box} I have installed R on my computer TRUEFALSE I have installed the RStudio IDE TRUEFALSE I have installed the dplyr R package TRUEFALSE\nIf you have done all of these things, you can skip this tutorial and go to the next one! :::\nInstall R How to install R Follow the video instructions here\nTest your knowledge ::: {.webex-check .webex-box} Is R free to download and use? TRUEFALSE\nWhere do you download R? www.rstudio.com/downloadcloud.r-project.orgwww.r-project.orgwww.r.com\nHow often should you update R? Everytime you use itAbout once a yearNever :::\nInstall RStudio How to install RStudio RStudio is an Integrated Development Environment for R. What does that mean? Well, if you think of R as a language, which it is, you can think of RStudio as a program that helps you write and work in the language. RStudio makes programming in R much easier and I suggest that you use it!\nFollow the video instructions here\nTest your knowledge ::: {.webex-check .webex-box} What is the RStudio IDE? An application that makes it easier to use R.An application that let’s you use R without writing any codeA spreadsheet program like Microsoft Excel.Another name for R\nIs the RStudio IDE free to download and use? TRUEFALSE\nWhere do you download RStudio? www.rstudio.com/downloadcloud.r-project.orgwww.r-project.orgcran.rstudio.org\nDo you need to install R if you already have RStudio? TRUEFALSE :::\nInstall Packages How to install R packages Follow the video instructions here\nTest your knowledge ::: {.webex-check .webex-box} What command do you use to install packages? library()install.packages()There is no command. You must visit cran.r-project.org and download packages manually.\nHow often do you need to install a package on your computer? Every time you restart REvery time you restart your computerOnly once. Afterwards, R can find it on your hard drive as needed.Never, as long as you are connected to the internet.\nWhat command do you use to load a package into your R session? package()library()install.packages() :::\n","date":1707955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707955200,"objectID":"47728ac26f5df1fd79f4c97e46fcdabc","permalink":"https://models4data2theory.github.io/courses/prework_01_install_r/","publishdate":"2024-02-15T00:00:00Z","relpermalink":"/courses/prework_01_install_r/","section":"courses","summary":"Before you arrive at RMBL.\nTutorial on setting up R and Rstudio.\n","tags":null,"title":"Prework - R and RStudio","type":"book"},{"authors":null,"categories":null,"content":"Before you arrive at RMBL.\nIntro to data structures, help pages, and variable types in R.\nOverview In this tutorial, you will learn how to use R to inspect the contents of a data frame or tibble. Data frames and tibbles are R’s structures for storing tabular data; if you inherit a tabular dataset in R, it will almost certainly come as one of these structures.\nHere, you will learn how to do three things with data frames and tibbles:\n Look at the contents of a data frame or tibble Open a help page that describes a data frame or tibble Identify the variables and their types in a tibble  You will also meet the palmerpenguins and nycflights datasets. These datasets appear frequently in R examples.\nThe readings in this tutorial follow R for Data Science, sections 3.2 and 5.1.\nData frames What is a data frame? A data frame is a rectangular collection of values, usually organized so that variables appear in the columns and observations appear in rows.\nHere is an example: the penguins data frame contains observations collected and published by Dr. Kristen Gorman from Palmer Station, a long-term environmental research site in Antarctica. The data frame contains 344 rows and 8 columns. Each row represents a penguin, and each column represents a variable that describes the penguin. Each penguin is one of three different species.\n   Typing penguins into the R console prints the header of the penguins data frame.\n## # A tibble: 344 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen NA NA NA NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 ## 6 Adelie Torgersen 39.3 20.6 190 3650 ## 7 Adelie Torgersen 38.9 17.8 181 3625 ## 8 Adelie Torgersen 39.2 19.6 195 4675 ## 9 Adelie Torgersen 34.1 18.1 193 3475 ## 10 Adelie Torgersen 42 20.2 190 4250 ## # ℹ 334 more rows ## # ℹ 2 more variables: sex \u0026lt;fct\u0026gt;, year \u0026lt;int\u0026gt; A note about palmerpenguins The code above worked because I’ve already loaded the palmerpenguins package in this tutorial: penguins comes in the palmerpenguins package. If you would like to look at penguins on your own computer, you will need to first load palmerpenguins. You can do that in two steps:\n Run install.packages(\u0026#39;palmerpenguins\u0026#39;) to install palmerpenguins if you do not yet have it. Load the package with the library(palmerpenguins) command. Run the command data(package = \u0026#39;palmerpenguins\u0026#39;) to load the penguins data frame into your R session.  After that, you will be able to access any dataset contained in the palmerpenguins package—until you close R.\nOne thing to notice Did you notice how much information was inside penguins? Me too. Sometimes the contents of a data frame are hard to interpret. Let’s get some help with this…\nHelp pages How to open a help page You can learn more about penguins by opening its help page. The help page will explain where the palmerpenguins dataset comes from and what each variable in the penguins data frame describes. To open the help page, type ?penguins in the code chunk below and then click “Run Code”.\nThe ? syntax You can open a help page for any object that comes with R or with an R package. To open the help page, type a ? before the object’s name and then run the command, as you did with ?penguins. This technique works for functions, packages, and more. If you want to specify getting help for a function or dataset in a particular package, you can use the :: operator. For example, ?dplyr::filter will open the help page for the filter() function in the dplyr package.\nNotice that objects created by you or your colleagues will not have a help page (unless you make one).\nExercises Please answer the following questions.\n::: {.webex-check .webex-box} What does the bill_depth_mm variable of penguins describe? Read the help for ?penguins to find out. The depth below the surface that the penguin dives to catch fishThe species of penguinThe distance across the bill from the chin to the top of the bill\nHow many rows are in the data frame named penguins? 343003443344\nHow many columns are in the data frame named penguins? 348010 :::\nData types Type codes Let’s return to the penguins data frame. Run the code chunk below to see the first few rows of penguins again.\npenguins ## # A tibble: 344 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen NA NA NA NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 ## 6 Adelie Torgersen 39.3 20.6 190 3650 ## 7 Adelie Torgersen 38.9 17.8 181 3625 ## 8 Adelie Torgersen 39.2 19.6 195 4675 ## 9 Adelie Torgersen 34.1 18.1 193 3475 ## 10 Adelie Torgersen 42 20.2 190 4250 ## # ℹ 334 more rows ## # ℹ 2 more variables: sex \u0026lt;fct\u0026gt;, year \u0026lt;int\u0026gt; Did you notice that …","date":1707955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707955200,"objectID":"ae243b22fb9dc3e9c9ce918e757de966","permalink":"https://models4data2theory.github.io/courses/prework_02_data_basics/","publishdate":"2024-02-15T00:00:00Z","relpermalink":"/courses/prework_02_data_basics/","section":"courses","summary":"Before you arrive at RMBL.\nIntro to data structures, help pages, and variable types in R.\n","tags":null,"title":"Prework - R Data Basics","type":"book"},{"authors":null,"categories":null,"content":"     Analysis of structure\nMotivation Ecological networks offer a powerful approach to comprehensively analyze entire systems comprising hundreds of species and their thousands of interactions. There are almost infinite ways in which hundreds of species can possibly interact. Networks allow to determine the specific, non-random interaction structure that actually occur in nature of those almost infinite possibilities. These networks also allow the study of the interplay between structure and dynamics of complex systems of interacting species, shedding light on how this interplay influences system responses to perturbations.\nRequired R-packages # PACKAGE LIST: Packages \u0026lt;- c(\u0026#34;igraph\u0026#34;, \u0026#34;tidyverse\u0026#34;, \u0026#34;knitr\u0026#34;, \u0026#34;kableExtra\u0026#34;, \u0026#34;evaluate\u0026#34;, \u0026#34;webexercises\u0026#34;, \u0026#34;vegan\u0026#34;, \u0026#34;bipartite\u0026#34;, \u0026#34;viridis\u0026#34;, \u0026#34;rmarkdown\u0026#34;, \u0026#34;gridGraphics\u0026#34;) # LOAD PACKAGES: lapply(Packages, library, character.only = TRUE) # SUPPRESS UNHELPFUL `dplyr` MESSAGES:  options(dplyr.summarise.inform = FALSE) # SAVE PACKAGE WARNING MESSAGES # this saves messages associated with package loading; display at the end # `evaluate` package pkg.load.msgs = evaluate(lapply(Packages, library, character.only = T)) Terminology A network consists of nodes and edges, where nodes represent discrete entities like people, computers, cities, or species, and edges (or links) represent the connections between these entities. Networks can be weighted or unweighted, depending on whether the connections have associated values or not. In weighted networks, the edges have numerical values that indicate the strength or distance of the connection between nodes. In the case of plant-pollinator networks, that weight has traditionally been the number or fraction of visits or pollen transported.\nNetworks can also be directed or undirected. In directed networks, such as food webs, the connections between nodes have a specific direction, such as the flow of energy, indicating a one-way relationship. In undirected networks, such as mutualistic networks, the connections are bidirectional, showing a two-way relationship between nodes (i.e., reciprocal benefits). We will see later that the reciprocal benefits between plant and pollinator species can be decomposed into the mechanisms by which those benefits are provided, which can convert the bidirectional links between species into two unidirectional links (i.e., consumption of floral rewards and pollination services).\nNetworks can also be unipartite or bipartite. Unipartite networks such as food webs consist of a single set of nodes (species), where edges can connect any pair of nodes within that set (any species can potentially be eaten by others). On the other hand, nodes in bipartite networks are divided into two disjoint sets, such as plants and pollinators, and edges (representing which pollinator species visits which plant species) only connect nodes from different sets (e.g., plants cannot visit other plants).\nBelow, there is an illustration of a plant-pollinator system represented as a bipartite network, with three plant and three pollinator species.\nEcological networks can be represented in various ways including a graph (as shown in the image above) or a matrix. Being able to switch between graph (network) and matrix form is powerful for understanding the full suite of network metrics we will see later.\nExercise 1.1: Using the bipartite network graph above, draw the corresponding matrix for the network. Assume that matrix rows represent animal species while matrix columns represent plant species. In the matrix cells, use 1’s to indicate an interaction between that animal and plant species and 0’s or blanks to indicate no interaction between species.\nNetwork data This workshop is focused on the integration of empirical data and theory in pollination networks. An important first step toward that integration is to know how to take empirical data and convert them into the standardized matrix format that is used in most packages and functions. For mutualistic networks like plant-pollinator networks, as discussed above, that format is a bipartite matrix with plants as rows, pollinators as columns, and (typically) counts of interactions filling the matrix.\nTypically, empirical data collected on ecological networks take the form of an edge list. This is the case for pollination networks in particular. To collect pollination network data, we are typically observing a set of flowers. When a flower visitor (presumed pollinator) visits a plant, we would record on a data sheet or field notebook the identity of the plant species and the identity of the flower visitor species. (In the field, we might capture an insect pollinator for later identification, but the idea remains the same, that at some point we would have a data sheet with the identities of the plants and the pollinators).\nSimilarly, you could also have an edge list created through pollen DNA metabarcoding; while you might need to play around with the formatting a bit it is common to end up …","date":1724284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724284800,"objectID":"9c58dcff331002096637ac5345b42f5d","permalink":"https://models4data2theory.github.io/courses/wkshp_networks/","publishdate":"2024-08-22T00:00:00Z","relpermalink":"/courses/wkshp_networks/","section":"courses","summary":"     Analysis of structure\n","tags":null,"title":"Networks","type":"book"},{"authors":null,"categories":null,"content":"Fitting models to data\n$$ \\newcommand{\\L}{\\mathcal{L}} $$\nMotivation A powerful approach to theory-data integration is the use of statistical methods that directly combine empirical data with the mechanistic models of theoretical ecology. This is the world of model-fitting.\nPerhaps we performed a study in which we counted the number of pollinator visits the flowers of a focal plant species received over a range of different plant densities and now wish to characterize the relationship between these variables. (To keep things simple, we’ll assume each plant has only a single flower.) Or perhaps we performed an experiment in which we varied the number of pollinator visits that the flowers of the plant species received and are now interested in characterizing how this variation in visits influenced ovule fertilization success (i.e. the proportion of ovules in each flower that were successfully fertilized).\nIn the past, the common way to characterize any such relationship among variables was to use linear or non-linear least-squares regression (including polynomial regression), extending more recently to mixed effects models. Generalized linear models and generalized additive models have also become popular, largely because they can accommodate non-Gaussian error structures and flexible, non-linear relationships.\nBut these types of statistical models are generally not “mechanistic”; their functional forms are not derived from “first-principles” ecological theory. Instead, these types of models are by and large only “descriptive” in nature.\nTheoreticians, on the other hand, have derived many non-statistical (deterministic) mathematical equations to encapsulate how different biological processes should/could influence the patterns we see in nature. Our goal is to develop the skills to (1) fit such mechanistic models to data in order to obtain best-fitting parameter estimates while accommodating process-appropriate error structures, and (2) compare the relative performance of several such models in order to identify those that perform best at representing the data.\nWe will achieve these things using the principle of maximum likelihood and an information-theoretic model-comparison approach. Other approaches for model fitting and comparison — such as Bayesian statistics — are often used to accommodate complex data structures and for other pragmatic and epistomological reasons, but those are beyond what we will cover. That said, most of the principles that we will cover are directly relevant to these other approaches as well.\nOverview To understand the principle of maximum likelihood, we first need to understand some fundamentals regarding probability distributions and likelihood functions. We’ll then see how theory models can be incorporated into likelihood functions to convert them from deterministic models to statistical models. It’s this conversion that permits us to fit them to data. We will then develop our intuition for maximum likelihood parameter estimation (i.e. model fitting) by first doing it analytically and then learning to use numerical optimization.\nHaving fit several models to a dataset, we will then dip our toes into the methods of comparing their relative performance using information criteria.\nSkip down to the end result to see where we’re headed.\nRequired R-packages In principle, everything we’ll discuss can be accomplished using functions that come pre-loaded in base R, but we’ll make use of the bbmle package for a few conveniences at the very end.\n# install.packages(\u0026#39;bbmle\u0026#39;, dependencies = TRUE) # use to install if needed library(bbmle) ## Loading required package: stats4 Fundamentals We’re going to start by assuming our focal response variable doesn’t vary in response to any possible covariates at all. Doing so is useful in helping us think about the different types of probability distributions there are, and which may be best in representing the type of stochastic processes that are likely to have generated our data.\nProbability distributions Our two example data sets above share some things in common because they both represent (or are derived from) counts of things. Counts are integer-valued (i.e. 0, 1, 2, 3, …) and can’t be negative. The proportion of fertilized ovules is derived from two counts: the count of fertilized ovules and the total count of available ovules. Count data are a very common type of data in ecology, so we’ll focus on them for our purposes.\nAmong the simplest and most appropriate probability distributions to represent such data are the Poisson and binomial probability distributions. Because they represent counts, they are discrete distributions.\nThe Poisson distribution The Poisson distribution would be appropriate for our dataset in which the count of visitations is our response variable. It is written as $$ Pr(k|\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$ and expresses the probability that $k$ events will occur in some interval of time (i.e. that the count of …","date":1724284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724284800,"objectID":"ec2c5709147baed9ba2f496c320224e9","permalink":"https://models4data2theory.github.io/courses/wkshp_interactions/","publishdate":"2024-08-22T00:00:00Z","relpermalink":"/courses/wkshp_interactions/","section":"courses","summary":"Fitting models to data\n","tags":null,"title":"Interactions","type":"book"},{"authors":null,"categories":null,"content":"Dynamics and stability\nThroughout, we will use the symbol $N$ to represent population size, as it does in nearly all population models in ecology.\nFor a start preceding the introduction of exponential growth, see the Of Potential Interest page.\nRequired R-packages We’ll need the deSolve package to integrate our differential equations with respect to time.\n# install.packages(\u0026#39;deSolve\u0026#39;, dependencies = TRUE) # use to install if needed library(deSolve) Exponential growth We will take as our starting point the differential equation,\n$$ \\frac{dN}{dt} = rN . $$ The left-hand-side of this equation is little more than a tangent slope: the change in population size given a change in time (i.e. how much the population size changes over a small amount of time).\nThe right hand size is a product of the population size $N$ (at any given instant in time) and $r$ is the intrinsic per capita growth rate. The intrinsic growth rate is nothing more than the difference between the rate at which the average individual gives birth, $b$, and the rate at which the average individual die, $d$. Together, they left and right-hand sizes of the equation represent the model of exponential growth.\nThe key to the exponential model is that the per capita birth and death rates (and thus $r$) are themselves independent of $N$. As a result, the population will growth if $r$ is net positive ($b \u0026gt; d$) and will exhibit exponential growth. Conversely, the population will shrink if $r$ is net negative ($b \u0026lt; d$) and will exhibit exponential decay.\nProjections To use the differential equation $\\frac{dN}{dt}=rN$ to project population sizes into the future we need to integrate the differential equation. Integrating from time $0$ to some time $T$ in the future, and assuming an initial population size at time zero of $N_0$, we get:\n$$ \\int_0^T \\frac{dN}{dt} dt = \\int_0^T r N dt \\implies N_T = N_0e^{rT}, $$ where $e$ is Euler’s number aka the base of the natural logarithm, which rounded to 5 digits is: 2.71828. (Think of Euler’s number $e$ as the anti-logarithm $ln$ or $log_e$, just like $2^x$ is the anti-logarithm of $log_2$.) Euler’s number is deeply rooted to multiplicative (exponential) processes.\nThe fact that an exponential shows up in the equation is why the modelis referred to as the model of exponential growth.\nIntegration Analytically integrating $\\frac{dN}{dt}$ to obtain a projection equation for the exponential model is relatively straightforward. Doing so is also possible for other models, such as the Logistic model that we will look at next. However, for most population dynamic models in ecology (especially multi-species models), analytical integration isn’t possible. So what we want to do is to develop a platform for modeling population dynamics that allows us to numerically solve integration problems (i.e. solve with calculations done by the computer rather than analytically), in a way that is extensible to much more complex problems. And to learn such approaches, it is definitely best to start with a simple model—and the extremely simple exponential growth model is perfect for this.\nThe tool we will work with is the ode() function of the deSolve package. deSolve implements multiple different numerical methods for solving ODEs (ordinary differential equations), which are the kinds of equations we will be working with in this workshop (equations that have $\\frac{dN}{dt}$ on the left-hand side). The deSolve package is very powerful and allows us to numerically solve even very complex multi-species network models (which we will be working up to throughout the day). But that flexibility means that it has a complex structure, which can admittedly be somewhat confusing when you are first starting to use it.\nThe function ode() requires a minimum of four input arguments, ode(y, times, func, parms):\n y is initial starting size of the variable (i.e. $N(0)$) times are the vector of time points $t$ at which we want ode to spit out the values of $N(t)$  e.g., times = 1:100 or times = seq(from = 1, to = 200, by = 0.2)   func is our ODE model for $dN/dt$ (written as a function with its own arguments) parms is a vector of the ODE model’s named parameters  The argument func (i.e. our ODE model) that we provide ode must be defined in a particular way that may feel a little redundant with the input that we pass to the ode function because they have to be working in parallel. The arguments that the function must have are (in order): (1) times; (2) the variable(s)—here, population size; and (3) the parameters used in our model.\nIn our code below, we will also take advantage of a facet of R that is not very well known. You can create a vector in R where you name the elements, for example my.vector = c(marmot = 3.2, pika = 47.6, ground.squirrel = 18.4). With a named vector, you can then access the elements via their name indicated with quotation marks: for the example above if you entered my.vector[\u0026#39;pika\u0026#39;] you would get back 47.6. We can use that with our …","date":1724371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724371200,"objectID":"544928dd7bfffef9991523d51b3b14c8","permalink":"https://models4data2theory.github.io/courses/wkshp_dynamics/","publishdate":"2024-08-23T00:00:00Z","relpermalink":"/courses/wkshp_dynamics/","section":"courses","summary":"Dynamics and stability\n","tags":null,"title":"Dynamics","type":"book"},{"authors":null,"categories":null,"content":"Supplementary materials\n$$ \\newcommand{\\L}{\\mathcal{L}} $$\nModel fitting Probability distributions Mass vs. density For discrete probability distributions, $P(O | \\theta)$ is typically referred to as a probability mass function. Given the parameter(s) $\\theta$, each integer value of an outcome $O$ (i.e. the discrete random variable) has some probability (some “mass”) of occurring.\nIn contrast, for continuous probability distributions, we instead refer to probability density functions, $f(O | \\theta)$. That’s because the probability of any specific value of a continuous random variable is zero! Instead, there is only a non-zero probability of the random variable falling within some interval of values. The higher the probability density over that interval, the higher the probability of observing a measurable value from within it.\nLikelihood functions The distinction between probability mass functions and probability density functions is relevant to the likelihood functions for discrete and continuous random variables. For discrete variables (as we will focus on in class), the likelihood of the parameter(s) given the data is equal to the probability of the data given the parameter(s), $$ L(\\theta | O) = P(O | \\theta). $$ For continuous variables, we maximize the likelihood of the parameter given the data by finding the parameter that maximizes the probability density function. That is, we maximize $$ L(\\theta | O) = f(O | \\theta). $$\nAnalytical MLE for Poisson Given $n$ observations (counts) from a process presumed to be well-described by the Poisson, we have that $$ -\\ln \\L(\\lambda |k) = -\\sum_i^n \\ln \\left (\\frac{\\lambda^{k_i} e^{-\\lambda}}{k_i!} \\right) . $$ Remembering that logarithms transform multiplicative processes into additive processes, we can write this as $$ -\\ln \\L(\\lambda |k) = -\\sum_i^n \\left ( \\ln ( \\lambda^{k_i} ) + \\ln (e^{-\\lambda} ) - \\ln (k_i!) \\right). $$ Since $\\ln x^y = y \\ln x$ and $\\ln e^x = x$, we can simplify this to $$ -\\ln \\L(\\lambda |k) = -\\sum_i^n \\left ( k_i \\ln (\\lambda) -\\lambda - \\ln (k_i!) \\right). $$ Distributing the summation, we get $$ -\\ln \\L(\\lambda |k) = -\\sum_i^n \\left ( k_i \\ln \\lambda \\right) + n\\lambda + \\sum_i^n \\ln (k_i!). $$ Now take the derivative with respect to $\\lambda$, set it equal to zero, and solve for $\\lambda$: $$ \\frac{d -\\ln \\L(\\lambda | k)}{d \\lambda} = - \\frac{1}{\\lambda} \\sum_i^n k_i + n = 0 \\implies \\lambda = \\frac{\\sum_i^n k_i}{n}, $$ which is the mean value of all the $k_i$ counts!\nOur analytically-solved maximum likelihood estimator for $\\lambda$, which we will symbolize by $\\hat{\\lambda}$, is therefore $$ \\hat{\\lambda} = \\frac{\\sum_i^n k_i}{n}. $$ This is nothing more than a function, think $\\hat{\\lambda}(k,n)$, to which we provide a vector of observed $k$ counts and their $n$ number (the vector’s length) as inputs.\nDynamics Building exponential growth Population models are focused on rates of births and deaths.\nLet’s start out by considering a “closed” population, with no immigration or emigration.\nWe will set $B$ = births and $D$ = deaths; right now these are terms for the entire population, overall how many births happened and how many deaths happened?\nA simple population growth model can be formulated by stating the obvious, starting out with the number of individuals in a population at a defined time that we will call $t$: in the next time period of interest $(t+1)$—for example, one year later—the population size $(N_{t+1})$ will be the current population size $(N_t)$ plus the births $(B)$ that occur between time $t$ and time $t+1$, minus the deaths $(D)$ that occur in that time period.\nWe can write this model formally as $$ N_{t+1} = N_t + B - D. $$\nThus, if you know the estimated birth and death rates in the coming time period, as well as the current population size, it is easy to calculate what the population size will be for the next time point.\nThe equation above is what we might call a difference equation: the difference between the population size of our target species at two discrete points in time. For many species, especially those with highly seasonal life cycles like annual plants, it makes sense to model them in discrete time.\nAt the same time, for species with overlapping generations, especially those that don’t have seasonal reproductive patterns, it makes sense instead to model them in continuous time. It is also mathematically much more tractable to use continuous-time models. For the rest of our discussion of population dynamics, we will focus on continuous-time models.\nIn thinking about continuous-time models, we move from difference equations like the one presented above to differential equations that are focused on on the change in population size over some continuous swath of time. Calculus is well-suited for this and from here on out, we will use calculus notation to think about the differential equations involved in how population size changes over time, designated as: $\\frac{dN}{dt}$. Remember that the $d$ in …","date":1724371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724371200,"objectID":"07207b860dd0272a9774dc620d3ec93e","permalink":"https://models4data2theory.github.io/courses/potential_use_or_interest/","publishdate":"2024-08-23T00:00:00Z","relpermalink":"/courses/potential_use_or_interest/","section":"courses","summary":"Supplementary materials\n","tags":null,"title":"Of Potential Interest","type":"book"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://models4data2theory.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]